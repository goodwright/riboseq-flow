import os
import snakemake.io
import glob

# conda activate snakemake
#### sbatch -N 1 -J snake --mem=8GB -t 24:00:00 --wrap="snakemake -s snakemake2.yaml -k --cluster 'sbatch {params.cluster}' --jobs 200 --configfile snakeconfig.yaml"

(SAMPLES,READS,) = glob_wildcards("fastq/{sample}_R{read}_001.fastq.gz")
READS=["1","2"]

#print(SAMPLES)

rule all:
    input: 
      expand("snake2/aligned/{sample}Aligned.sortedByCoord.out.bam",sample=SAMPLES),
      expand("snake2/mapping_length_analysis/{sample}.csv",sample=SAMPLES),
      expand("snake2/genome_dedup/{sample}Aligned.sortedByCoord.out.bam",sample=SAMPLES),
      expand("snake2/tx_dedup/{sample}Aligned.sortedByCoord.out.bam",sample=SAMPLES),
      expand("snake2/mapping_length_analysis/after_premapping_{sample}.csv",sample=SAMPLES),
      expand("snake2/mapping_length_analysis/after_dedup_{sample}.csv",sample=SAMPLES),
      expand("snake2/ribocutter/ribocutter_{sample}.csv", sample=SAMPLES),
      expand("snake2/ribocutter/ribocutter_min23_{sample}.csv", sample=SAMPLES)


rule bowtie2_index:
    input:
        genome_fasta=config["smallrna_genome"]
    output:
        index=config["smallrna_indexname"]+".1.bt2" # just include this so that snakemake can check if it's made it, it will actually produce 6 or more files probably, but we only need one
    params:
        indexname=config["smallrna_indexname"],
        cluster="-J bt2idx -N 1 --mem=16G -t 1:00:00 -o snake2/slurm/bowtie_index.slurm"
    threads:
        4
    shell:
        "bowtie2-build --threads {threads} {input.genome_fasta} {params.indexname}"


# remove 5 bases and move to header for umi tools
rule cutadapt:
  input:
    r1 = "fastq/{sample}_R1_001.fastq.gz"
  output:
    o1 = "snake2/cut/{sample}.fastq.gz"
  threads: 8

  params:
    cluster = "-J cut --cpus-per-task=8 --mem=8G -t 8:00:00 -o snake2/slurm/cutadapt_{sample}.txt"

  shell:
    """
    cutadapt -u 5 --rename='{{id}}_umi:{{cut_prefix}}' -a AAAAAAAAAAA -o {output.o1} -j {threads} -q 20 {input.r1}
    """

# remove 3 bases
rule cutadapt_rGrGrG:
  input:
    r1 = "snake2/cut/{sample}.fastq.gz"
  output:
    o1 = "snake2/cut2/{sample}.fastq.gz"
  threads: 8

  params:
    cluster = "-J cut --cpus-per-task=8 --mem=8G -t 8:00:00 -o snake2/slurm/cutadapt_rGrGrG_{sample}.txt"

  shell:
    """
    cutadapt -u 3 -o {output.o1} -j {threads} --minimum-length 20 {input.r1}
    """

# Premap
rule bowtie2_map:
    input:
        fastq = "snake2/cut2/{sample}.fastq.gz",
        indexfile=config["smallrna_indexname"]+".1.bt2"
    output:
        unmapped="snake2/unmapped/{sample}.fastq.gz"
    threads:
        8
    params:
        bowtie2_index=config["smallrna_indexname"],
        sam="snake2/premapping_mapped/{sample}.sam",
        cluster="-J bt2_map -N 1 --mem=32G -t 6:00:00 -o snake2/slurm/bowtie2_{sample}.slurm",
        map_params="--norc --no-unal --very-sensitive-local -N 1"
    shell:
        """
        bowtie2 {params.map_params} -p {threads} --un-gz {output.unmapped} -x {params.bowtie2_index} -U {input.fastq} -S {params.sam}
        rm {params.sam}
        """





rule star_map:
  input:
    r1 = "snake2/unmapped/{sample}.fastq.gz"
  output:
    bam = "snake2/aligned/{sample}Aligned.sortedByCoord.out.bam",
    tx_sorted = "snake2/aligned/{sample}Aligned.toTranscriptome.sorted.out.bam"

  threads: 8

  params:
    cluster = "-J starmap --mem=64G -t 8:00:00 -o snake2/slurm/STAR_{sample}.txt",
    bam = "snake2/aligned/{sample}",
    tx = "snake2/aligned/{sample}Aligned.toTranscriptome.out.bam"


  shell:
      """
      STAR --runThreadN {threads} \
      --genomeDir /camp/lab/ulej/home/users/wilkino/genomes/hs/gencode_29/star_index/ \
      --readFilesIn {input.r1} \
      --readFilesCommand zcat \
      --outFileNamePrefix {params.bam} \
      --outSAMtype BAM SortedByCoordinate\
      --seedSearchStartLmax 15 \
      --outReadsUnmapped Fastx\
      --genomeLoad NoSharedMemory \
      --outFilterMultimapNmax 1\
      --outFilterMismatchNoverReadLmax 0.08\
      --alignEndsType EndToEnd \
      --quantMode TranscriptomeSAM \
      --outSAMattributes Standard
      samtools index {output.bam}
      samtools sort -@ {threads} {params.tx} > {output.tx_sorted}
      rm {params.tx}
      """


rule genome_dedup:
    input:
        bam="snake2/aligned/{sample}Aligned.sortedByCoord.out.bam"
    output:
        bam="snake2/genome_dedup/{sample}Aligned.sortedByCoord.out.bam"
    params:
        bam_unsorted="snake2/genome_dedup/{sample}.Aligned.sortedByCoord.out.unsorted.bam",
        cluster="-J gen_dedup -N 1 --mem=32G -t 4:00:00 -o snake2/slurm/genome_dedup_{sample}.slurm"
    shell:
        """
        umi_tools dedup --umi-separator 'umi:' -I {input.bam} -S {params.bam_unsorted}
        samtools sort -@ {threads} {params.bam_unsorted} > {output.bam}
        samtools index {output.bam}
        rm {params.bam_unsorted}        
        """

rule transcriptome_dedup:
    input:
        bam="snake2/aligned/{sample}Aligned.toTranscriptome.sorted.out.bam"
    output:
        bam="snake2/tx_dedup/{sample}Aligned.sortedByCoord.out.bam"
    params:
        bam_unsorted="snake2/tx_dedup/{sample}.Aligned.sortedByCoord.out.unsorted.bam",
        cluster="-J tx_dedup -N 1 --mem=32G -t 4:00:00 -o snake2/slurm/tx_dedup_{sample}.slurm"
    shell:
        """
        samtools index {input.bam}
        umi_tools dedup --umi-separator 'umi:' -I {input.bam} -S {params.bam_unsorted}
        samtools sort -@ {threads} {params.bam_unsorted} > {output.bam}
        samtools index {output.bam}
        rm {params.bam_unsorted}        
        """

rule mapping_length_analysis:
  input:
    bam="snake2/aligned/{sample}Aligned.sortedByCoord.out.bam", # before deduplication
    fastq="snake2/cut/{sample}.fastq.gz"
  output:
    csv = "snake2/mapping_length_analysis/{sample}.csv"
  params:
    cluster="-J length_analysis -N 1 --mem=8G -t 8:00:00 -o snake2/slurm/mapping_length_analysis_{sample}.slurm"
  shell:
    """
    python3 mapping_length_analysis.py -f {input.fastq} -b {input.bam} -o {output.csv}
    """

rule mapping_length_analysis_after_premapping:
  input:
    bam="snake2/aligned/{sample}Aligned.sortedByCoord.out.bam", # before deduplication
    fastq="snake2/unmapped/{sample}.fastq.gz"
  output:
    csv = "snake2/mapping_length_analysis/after_premapping_{sample}.csv"
  params:
    cluster="-J length_analysis -N 1 --mem=8G -t 8:00:00 -o snake2/slurm/mapping_length_analysis_premap_{sample}.slurm"
  shell:
    """
    python3 mapping_length_analysis.py -f {input.fastq} -b {input.bam} -o {output.csv}
    """


rule mapping_length_analysis_after_dedup:
  input:
    bam="snake2/genome_dedup/{sample}Aligned.sortedByCoord.out.bam"
  output:
    csv = "snake2/mapping_length_analysis/after_dedup_{sample}.csv"
  params:
    cluster="-J length_analysis -N 1 --mem=8G -t 8:00:00 -o snake2/slurm/mapping_length_analysis_dedup_{sample}.slurm"
  shell:
    """
    python3 mapping_length_analysis.py -b {input.bam} -o {output.csv}
    """


rule ribocutter:
  input:
    fastq="snake2/cut/{sample}.fastq.gz"  # before removing rGrGrG and length filtering
  output:
    csv = "snake2/ribocutter/ribocutter_{sample}.csv"
  params:
    cluster="-J ribocutter -N 1 --mem=8G -t 8:00:00 -o snake2/slurm/ribocutter_{sample}.slurm"
  shell:
    """
    ribocutter -i {input.fastq} -o {output.csv} --max_reads 1000000 -g 50
    """


rule ribocutter_min23:
  input:
    fastq="snake2/cut/{sample}.fastq.gz"  # before removing rGrGrG and length filtering
  output:
    csv = "snake2/ribocutter/ribocutter_min23_{sample}.csv"
  params:
    cluster="-J ribocutter -N 1 --mem=8G -t 8:00:00 -o snake2/slurm/ribocutter_min23_{sample}.slurm"
  shell:
    """
    ribocutter -i {input.fastq} -o {output.csv} --max_reads 1000000 -g 50 --min_read_length 23
    """