#sbatch -N 1 -J snake --mem=8GB -t 24:00:00 -o snakelogs/ribomap_%A.log --wrap="time snakemake -s snakefile.yaml -k --cluster 'sbatch {params.cluster}' --jobs 200 --latency-wait 60 --configfile samples_config.yaml"

rule all:
    input:
        expand(config["output_dir"] + "/results/STAR/logs/{sample}.Log.final.out", sample=config["samples"]),
        expand(config["output_dir"] + "/results/STAR/{sample}.Aligned.sortedByCoord.out.bam", sample=config["samples"]),
        expand(config["output_dir"] + "/results/genome_dedup/{sample}.Aligned.sortedByCoord.out.bam.bai", sample=config["samples"]),
        expand(config["output_dir"] + "/results/STAR/{sample}.Aligned.toTranscriptome.out.bam", sample=config["samples"]),
        expand(config["output_dir"] + "/results/transcriptome_dedup/{sample}.Aligned.toTranscriptome.out.bam.bai", sample=config["samples"]),
        expand(config["output_dir"] + "/results/premapping_mapped/{sample}.bam.seqs.gz", sample=config["samples"]),
        expand(config["output_dir"] + "/results/riboloco/{sample}.bedgraph", sample=config["samples"]),
        expand(config["output_dir"] + "/results/mapping_length_analysis/{sample}.csv", sample=config["samples"]),
        expand(config["output_dir"]+"/results/ribocutter/{sample}", sample=config["samples"]) 
        


# Create indexes
rule bowtie2_index:
    input:
        genome_fasta=config["smallrna_genome"]
    output:
        index=config["smallrna_indexname"]+".1.bt2" # just include this so that snakemake can check if it's made it, it will actually produce 6 or more files probably, but we only need one
    params:
        indexname=config["smallrna_indexname"],
        cluster="-J bt2idx -N 1 --mem=16G -t 1:00:00 -o slurm_logs/bowtie_index.slurm"
    threads:
        4
    shell:
        "bowtie2-build --threads {threads} {input.genome_fasta} {params.indexname}"




rule star_index:
    input:
        genome_fasta=config["genome"],
        gtf=config["genome_annot"]
    threads:
        8
    params:
        outdir=config["staridx_path"],
        cluster="-p hmem -J staridx -N 1 --mem 256G -c 8 -t 8:00:00 -o slurm_logs/staridx.slurm"
    output:
        index=config["staridx_path"]+"exonInfo.tab"
    shell:
        """
        STAR --runThreadN {threads} \
        --runMode genomeGenerate \
        --genomeDir {params.outdir} \
        --genomeFastaFiles {input.genome_fasta} \
        --sjdbGTFfile {input.gtf} \
        --outFileNamePrefix {params.outdir} \
        --sjdbGTFfeatureExon exon \
        --sjdbOverhang 100 \
        --limitGenomeGenerateRAM=200000000000 
        """


# Premap
rule bowtie2_map:
    input:
        fastq=lambda wildcards: config["samples"][wildcards.sample],
        indexfile=config["smallrna_indexname"]+".1.bt2"
    output:
        bam=config["output_dir"]+"/results/premapping_mapped/{sample}.bam",
        unmapped=config["output_dir"]+"/results/premapping_unmapped/{sample}.fastq.gz",
        seqs = config["output_dir"]  + "/results/premapping_mapped/{sample}.bam.seqs.gz"
    threads:
        8
    params:
        bowtie2_index=config["smallrna_indexname"],
        sam=config["output_dir"]+"/results/premapping_mapped/{sample}.sam",
        cluster="-J bt2_map -N 1 --mem=32G -t 6:00:00 -o slurm_logs/bowtie2_{sample}.slurm",
        map_params="--norc --no-unal --very-sensitive-local -N 1"
    shell:
        """
        bowtie2 {params.map_params} -p {threads} --un-gz {output.unmapped} -x {params.bowtie2_index} -U {input.fastq} -S {params.sam}
        samtools sort -o {output.bam} -O bam -@ {threads} {params.sam}
        samtools index {output.bam}
        samtools view {output.bam} | cut -f3-5,10 > {output.bam}.seqs
        gzip {output.bam}.seqs
        rm {params.sam}
        """
# samtools view snakemake_output/results/premapping_mapped/{sample}.bam | cut -f3-5,10



# Map to genome and transcriptome
rule star_map:
    input:
        message=config["staridx_path"]+"exonInfo.tab",
        fastq=config["output_dir"]+"/results/premapping_unmapped/{sample}.fastq.gz"
    output:
        bam=config["output_dir"]+"/results/STAR/{sample}.Aligned.sortedByCoord.out.bam",
        bam2=config["output_dir"] + "/results/STAR/{sample}.Aligned.toTranscriptome.out.bam",
        logfolder=config["output_dir"]+"/results/STAR/logs/{sample}.Log.final.out"
    params:
        star_index=config["staridx_path"],
        log=config["output_dir"]+"/results/STAR/{sample}.Log.final.out",
        outprefix=config["output_dir"]+"/results/STAR/{sample}.",
        cluster="-J starmap -N 1 --mem=32G -t 8:00:00 -o slurm_logs/starmap_{sample}.slurm"
    threads:
        8
    shell:
        """
        STAR --runThreadN {threads} \
        --genomeDir {params.star_index} \
        --readFilesIn {input.fastq} \
        --readFilesCommand zcat \
        --outFileNamePrefix {params.outprefix} \
        --outSAMtype BAM SortedByCoordinate\
        --seedSearchStartLmax 15 \
        --outReadsUnmapped Fastx\
        --genomeLoad NoSharedMemory \
        --outFilterMultimapNmax 1\
        --outFilterMismatchNoverReadLmax 0.08\
        --alignEndsType EndToEnd \
        --quantMode TranscriptomeSAM \
        --outSAMattributes Standard
        mv {params.log} {output.logfolder}
        """

# Deduplicate
rule genome_dedup:
    input:
        bam=config["output_dir"] + "/results/STAR/{sample}.Aligned.sortedByCoord.out.bam"
    output:
        bam=config["output_dir"] + "/results/genome_dedup/{sample}.Aligned.sortedByCoord.out.bam",
        bai=config["output_dir"] + "/results/genome_dedup/{sample}.Aligned.sortedByCoord.out.bam.bai",
        bed = config["output_dir"] + "/results/genome_dedup/{sample}.Aligned.sortedByCoord.out.bam.bed.gz"
    params:
        bam_unsorted=config["output_dir"] + "/results/genome_dedup/{sample}.Aligned.sortedByCoord.out.unsorted.bam",
        um=config["output_dir"] + "/results/genome_dedup/um.{sample}.Aligned.sortedByCoord.out.bam",
        cluster="-J gen_dedup -N 1 --mem=32G -t 4:00:00 -o slurm_logs/genome_dedup_{sample}.slurm",
        bed = config["output_dir"] + "/results/genome_dedup/{sample}.Aligned.sortedByCoord.out.bam.bed",
    shell:
        """
        samtools view -q 20 -h {input.bam} > {params.um} #-q 20 is probably unnecessary as we don't allow multimapping reads.
        umi_tools dedup --umi-separator 'rbc:' -I {params.um} -S {params.bam_unsorted}
        samtools sort -@ {threads} {params.bam_unsorted} > {output.bam}
        samtools index {output.bam} > {output.bai}
        rm {params.bam_unsorted}        
        bam2bed < {output.bam} | cut -f1-3,6 -d$'\t' > {params.bed}
        gzip {params.bed}
        """




rule transcriptome_dedup:
    input:
        bam=config["output_dir"] + "/results/STAR/{sample}.Aligned.toTranscriptome.out.bam"
    output:
        bam=config["output_dir"] + "/results/transcriptome_dedup/{sample}.Aligned.toTranscriptome.out.bam",
        bai=config["output_dir"] + "/results/transcriptome_dedup/{sample}.Aligned.toTranscriptome.out.bam.bai",
        bed=config["output_dir"] + "/results/transcriptome_dedup/{sample}.Aligned.toTranscriptome.out.bam.bed.gz"
    threads:
        8
    params:
        bam_unsorted=config["output_dir"] + "/results/transcriptome_dedup/{sample}.Aligned.toTranscriptome.out.unsorted.bam",
        cluster="-J tome_dedup -N 1 --mem=32G -t 4:00:00 -o slurm_logs/transcriptome_dedup{sample}.slurm",
        bam_temp=config["output_dir"] + "/results/transcriptome_dedup/{sample}.Aligned.toTranscriptome.out.temp.bam", 
        bed=config["output_dir"] + "/results/transcriptome_dedup/{sample}.Aligned.toTranscriptome.out.bam.bed" 
    shell:
        """
        samtools sort -@ {threads} {input.bam} > {params.bam_temp} #It's necessary to sort and index the transcriptome bam in order for UMI Tools to process it.
        samtools index {params.bam_temp}
        echo umitools
        umi_tools dedup --umi-separator 'rbc:' -I {params.bam_temp} -S {params.bam_unsorted}
        samtools sort -@ {threads} {params.bam_unsorted} > {output.bam}
        samtools index {output.bam} > {output.bai}
        rm {params.bam_temp}
        rm {params.bam_temp}.bai 
        bam2bed < {output.bam} | cut -f1-3,6 -d$'\t' > {params.bed}
        gzip {params.bed} 
        """



  #Rscript find_A_site_offsets.R snakemake_output/results/transcriptome_dedup/Br_Dis_1p5.Aligned.toTranscriptome.out.bam.bed.gz /camp/lab/ulej/home/users/wilkino/genomes/mouse/longest_proteincoding_transcript_mm_details.txt /camp/lab/ulej/home/users/wilkino/genomes/mouse/gencode_M22/longest_gencode22.fa yeh.csv snakemake_output/results/reference_pattern.csv 4 0.05




#### for bowtie transcriptome mapping

rule bowtie2_transcriptome_map:
    input:
      fastq = config["output_dir"]+"/results/premapping_unmapped/{sample}.fastq.gz"
    params:
      cluster="-J bt2_tx_map -N 1 --mem=32G -t 6:00:00 -o slurm_logs/bowtie_tx_map_{sample}.slurm",
      bowtie2_index=config["transcriptome_index"],
      sam=config["output_dir"]+"/results/bt_tx_mapped/{sample}.sam",
      map_params="--norc --no-unal --end-to-end -N 1"
    output:
      bam = config["output_dir"] + "/results/bt_tx_mapped/{sample}.bam"
    threads:
      8
    shell:
      """
      bowtie2 {params.map_params} -p {threads} -x {params.bowtie2_index} -U {input.fastq} -S {params.sam}
      samtools sort -o {output.bam} -O bam -@ {threads} {params.sam}
      samtools index {output.bam}
      rm {params.sam}
      """

rule bowtie2_dedup:
    input:
      bam=config["output_dir"] + "/results/bt_tx_mapped/{sample}.bam"
    output:
      bam = config["output_dir"] + "/results/bt_tx_dedup/{sample}.bam",
      bai = config["output_dir"] + "/results/bt_tx_dedup/{sample}.bam.bai",
      dummy_out = config["output_dir"] + "/results/bt_tx_dedup/{sample}.bed.gz"
    params:
      cluster="-J bt_dedup -N 1 --mem=32G -t 4:00:00 -o slurm_logs/bt_dedup_{sample}.slurm",
      good_map = config["output_dir"] + "/results/bt_tx_mapped/good_map_{sample}.bam",
      bam_unsorted = config["output_dir"] + "/results/bt_tx_mapped/unsorted_{sample}.bam",
      bed = config["output_dir"] + "/results/bt_tx_dedup/{sample}.bed"
    shell:
        """
        samtools view -q 20 -h {input.bam} > {params.good_map} #-q 20 is probably unnecessary as we don't allow multimapping reads.
        umi_tools dedup --umi-separator 'rbc:' -I {params.good_map} -S {params.bam_unsorted}
        samtools sort -@ {threads} {params.bam_unsorted} > {output.bam}
        samtools index {output.bam} > {output.bai}
        rm {params.bam_unsorted}        
        bam2bed < {output.bam} | cut -f1-3,6 -d$'\t' > {params.bed}
        gzip {params.bed}
        """


rule riboloco:
    input:
      bam=config["output_dir"] + "/results/transcriptome_dedup/{sample}.Aligned.toTranscriptome.out.bam"
    output:
      name = config["output_dir"]+"/results/riboloco/{sample}.bedgraph"
    params:
      cluster="-J riboloco -N 1 --mem=32G -t 8:00:00 -o slurm_logs/riboloco_{sample}.slurm",
      orf_file = config["orf_file"],
      tx_fasta = config["tx_fasta"],
      riboloco_info = config["riboloco_info"],
      dir = config["output_dir"] + "/results/riboloco/",
      output = "{sample}"
    shell:
      """
      riboloco -s {input.bam} -i {params.riboloco_info} -f {params.tx_fasta} -pg --save_stats -a 0.005 -d {params.dir} -o {params.output} -t 22_0:-6 22_1:-7 22_2:-5 21_0:-6 21_1:-7 21_2:-5 28_0:-12 29_0:-12 \
      -a 0.001 -ar 0.001
      """
      
rule mapping_length_analysis:
  input:
    bam=config["output_dir"] + "/results/STAR/{sample}.Aligned.sortedByCoord.out.bam", # before deduplication
    fastq=lambda wildcards: config["samples"][wildcards.sample]
  output:
    csv = config["output_dir"]+"/results/mapping_length_analysis/{sample}.csv"
  params:
    cluster="-J length_analysis -N 1 --mem=8G -t 8:00:00 -o slurm_logs/mapping_length_analysis_{sample}.slurm"
  shell:
    """
    mapping_length_analysis -f {input.fastq} -b {input.bam} -o {output.csv}
    """

rule ribocutter:
    input:
        fastq=lambda wildcards: config["samples"][wildcards.sample]
    output:
        csv = config["output_dir"]+"/results/ribocutter/{sample}"
    params:
        cluster="-J ribocutter -N 1 --mem=16G -t 8:00:00 -o slurm_logs/ribocutter_{sample}.slurm"
    shell:
        """
        ribocutter -i {input.fastq} --min_read_length 12 --max_read_length 35 --save_stats --stats_frac 0.00001 -o {output.csv}
        """
